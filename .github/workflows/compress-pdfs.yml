
name: PDF Compressor Bot

on:
  schedule:
    # Каждый день в 2:00 UTC (утром)
    - cron: '0 2 * * *'
    # И в 14:00 UTC (днем)
    - cron: '0 14 * * *'

  workflow_dispatch:
    inputs:
      source_folder:
        description: 'Mega folder path to process'
        required: false
        default: '/Shared items/WI/PDF/Input'
        type: string
      target_folder:
        description: 'Mega folder for compressed files'
        required: false
        default: '/Shared items/WI/PDF/Compressed'
        type: string
      compression_level:
        description: 'Compression level'
        required: false
        default: 'medium'
        type: choice
        options:
        - low
        - medium
        - high
      max_files:
        description: 'Maximum files to process in one run'
        required: false
        default: '50'
        type: string
      dry_run:
        description: 'Test run without making changes'
        required: false
        default: false
        type: boolean

env:
  MEGA_EMAIL: ${{ secrets.MEGA_EMAIL }}
  MEGA_PASSWORD: ${{ secrets.MEGA_PASSWORD }}
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
  TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  compress-pdfs:
    runs-on: ubuntu-latest
    timeout-minutes: 300  # 5 часов максимум

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install system dependencies
      run: |
        set -e
        sudo apt-get update
        sudo apt-get install -y ghostscript qpdf poppler-utils gnupg curl ca-certificates

        # Add MEGA official APT repo (detect Ubuntu version dynamically)
        . /etc/os-release
        echo "Detected Ubuntu ${VERSION_ID} (${VERSION_CODENAME})"
        curl -fsSL "https://mega.nz/linux/repo/xUbuntu_${VERSION_ID}/Release.key" | sudo gpg --dearmor -o /usr/share/keyrings/mega-archive-keyring.gpg
        echo "deb [signed-by=/usr/share/keyrings/mega-archive-keyring.gpg] https://mega.nz/linux/repo/xUbuntu_${VERSION_ID}/ ./" | sudo tee /etc/apt/sources.list.d/meganz.list
        sudo apt-get update
        sudo apt-get install -y megacmd

        # Install rclone
        echo "Installing rclone..."
        curl -fsSL https://rclone.org/install.sh | sudo bash

        # Verify installations
        echo "Verifying installations..."
        gs --version
        qpdf --version
        rclone version
        mega-version || mega-help || true

    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create temp directories
      run: |
        mkdir -p temp/{input,output,logs,backup}

    - name: Validate configuration
      run: |
        python src/config.py

    - name: Test components
      run: |
        echo "Testing PDF compressor..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from compressor import PDFCompressor
        from utils import setup_logging
        setup_logging(level='INFO')
        compressor = PDFCompressor(level='medium')
        info = compressor.get_compression_info()
        print('Available tools:', info['available_tools'])
        print('Configuration OK ✅')
        "

        echo "Testing rclone client..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from rclone_client import RcloneClient
        from utils import setup_logging
        setup_logging(level='INFO')
        print('RcloneClient module loaded successfully ✅')
        "

        echo "Testing MEGAcmd client import..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from megacmd_client import MegaWebDAVClient  # noqa: F401
        print('MegaWebDAVClient module loaded successfully ✅')
        "

    - name: "Diagnostic: Test Mega credentials"
      run: |
        echo "Running Mega credentials diagnostic..."
        python scripts/test_mega_credentials.py || true
        echo "Diagnostic complete (non-blocking)"

    - name: Run PDF compression
      env:
        SOURCE_FOLDER: ${{ github.event.inputs.source_folder || '/Shared items/WI/PDF/Input' }}
        TARGET_FOLDER: ${{ github.event.inputs.target_folder || '/Shared items/WI/PDF/Compressed' }}
        COMPRESSION_LEVEL: ${{ github.event.inputs.compression_level || 'medium' }}
        MAX_FILES: ${{ github.event.inputs.max_files || '50' }}
        DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
      run: |
        python src/main.py \
          --source "$SOURCE_FOLDER" \
          --target "$TARGET_FOLDER" \
          --level "$COMPRESSION_LEVEL" \
          --max-files "$MAX_FILES" \
          --log-file "temp/logs/compression.log" \
          --log-level "INFO" \
          $( [[ "$DRY_RUN" == "true" ]] && echo "--dry-run" || echo "" )

    - name: Generate report
      if: always()
      run: |
        python scripts/generate_report.py temp/logs/compression.log > temp/report.md

    - name: Send Telegram notification
      if: always() && env.TELEGRAM_BOT_TOKEN != ''
      run: |
        python scripts/send_notification.py temp/report.md

    - name: Upload logs as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: compression-logs-${{ github.run_number }}
        path: |
          temp/logs/
          temp/report.md
        retention-days: 30

    - name: Create GitHub Issue on failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');

          // Read log file
          let logContent = '';
          try {
            logContent = fs.readFileSync('temp/logs/compression.log', 'utf8');
          } catch (error) {
            logContent = 'Log file not found';
          }

          // Read statistics
          let statsContent = '';
          try {
            const statsPath = 'temp/logs/stats.json';
            const stats = JSON.parse(fs.readFileSync(statsPath, 'utf8'));

            const formatFileSize = (bytes) => {
              if (!bytes) return '0 B';
              const k = 1024;
              const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
              const i = Math.floor(Math.log(bytes) / Math.log(k));
              return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
            };

            const percentSaved = (stats.total_percent_saved != null)
              ? Number(stats.total_percent_saved).toFixed(1)
              : (stats.total_size_before > 0
                ? (((stats.total_bytes_saved || 0) / stats.total_size_before) * 100).toFixed(1)
                : '0.0');

            statsContent = `## 📊 Compression Results

✅ **Successfully processed:** ${stats.processed_files || 0} files
${(stats.failed_files || 0) > 0 ? `❌ **Failed:** ${stats.failed_files} files` : ''}
⏱️ **Duration:** ${Math.round(stats.duration || 0)} seconds
🗜️ **Compression level:** ${stats.compression_level || 'unknown'}

📊 **Space savings:**
- Before: ${formatFileSize(stats.total_size_before || 0)}
- After: ${formatFileSize(stats.total_size_after || 0)}
- Saved: ${formatFileSize(stats.total_bytes_saved || 0)} (${percentSaved}%)`;
          } catch (error) {
            statsContent = 'Statistics not available';
          }

          // Create Issue
          const issueDate = new Date().toISOString().split('T')[0];
          const issueTitle = 'PDF Compression Failed - ' + issueDate;
          const issueBody = '# PDF Compression Job Failed\n\n' +
            '**Run ID:** [${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n' +
            '**Triggered by:** ${{ github.event_name }}\n\n' +
            '**Parameters:**\n' +
            '- Source Folder: `${{ github.event.inputs.source_folder || ' + "'/Shared items/WI/PDF/Input'" + ' }}`\n' +
            '- Target Folder: `${{ github.event.inputs.target_folder || ' + "'/Shared items/WI/PDF/Compressed'" + ' }}`\n' +
            '- Compression Level: `${{ github.event.inputs.compression_level || ' + "'medium'" + ' }}`\n' +
            '- Max Files: `${{ github.event.inputs.max_files || ' + "'50'" + ' }}`\n\n' +
            statsContent + '\n\n' +
            '## Error Log (last 3000 characters):\n' +
            '```\n' +
            logContent.slice(-3000) + '\n' +
            '```\n\n' +
            '---\n' +
            '*This issue was created automatically by GitHub Actions*';

          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: issueTitle,
            body: issueBody,
            labels: ['bug', 'automated', 'pdf-compression']
          });

    - name: Post summary on success
      if: success() && github.event_name == 'workflow_dispatch'
      run: |
        set -e
        echo "## ✅ Compression Succeeded" >> $GITHUB_STEP_SUMMARY
        if [ -f temp/report.md ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          cat temp/report.md >> $GITHUB_STEP_SUMMARY
        elif [ -f temp/logs/stats.json ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Stats" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat temp/logs/stats.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
